{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'subtitle', 'author', 'url', 'text', 'time', 'date',\n",
      "       'difficulty', 'tags'],\n",
      "      dtype='object')\n",
      "                                               title subtitle  \\\n",
      "0  Астрономы нанесли на карту 25 тысяч сверхмасси...      NaN   \n",
      "1  Астрономы нашли пять гигантских собратьев Эты ...      NaN   \n",
      "2  Глицерин из электронных сигарет спровоцировал ...      NaN   \n",
      "\n",
      "             author                                            url  \\\n",
      "0  Александр Войтюк    https://nplus1.ru/news/2021/02/24/map-of-bh   \n",
      "1  Владимир Королев  https://nplus1.ru/news/2016/01/07/eta-carinae   \n",
      "2     Слава Гоменюк    https://nplus1.ru/news/2020/05/27/microends   \n",
      "\n",
      "                                                text   time      date  \\\n",
      "0  Астрономы подвели предварительные итоги низкоч...  10:23  24.02.21   \n",
      "1  Астрономы из Университета Огайо и Центра косми...  12:10  07.01.16   \n",
      "2  Глицерол и пропиленгликоль, входящие в состав ...  21:00  27.05.20   \n",
      "\n",
      "   difficulty                                         tags  \n",
      "0         3.7                               ['Астрономия']  \n",
      "1         3.2  ['Космос', 'Наука', 'Космические дневники']  \n",
      "2         4.3                     ['Медицина', 'Биология']  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"news_data.csv\")\n",
    "print(df.columns)\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "index_name = \"news\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс news успешно создан с русским анализатором\n"
     ]
    }
   ],
   "source": [
    "mapping = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"russian_stop\": {\n",
    "                    \"type\": \"stop\",\n",
    "                    \"stopwords\": \"_russian_\"  # стандартные русские стоп-слова\n",
    "                },\n",
    "                \"russian_stemmer\": {\n",
    "                    \"type\": \"stemmer\",\n",
    "                    \"language\": \"russian\"\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"russian_custom\": {\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"russian_stop\",\n",
    "                        \"russian_stemmer\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"text\", \"analyzer\": \"russian_custom\"},\n",
    "            \"subtitle\": {\"type\": \"text\", \"analyzer\": \"russian_custom\"},\n",
    "            \"author\": {\"type\": \"keyword\"},\n",
    "            \"url\": {\"type\": \"keyword\", \"index\": False},\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"russian_custom\"},\n",
    "            \"time\": {\"type\": \"keyword\"},\n",
    "            \"date\": {\"type\": \"date\", \"format\": \"dd.MM.yy||yyyy-MM-dd\"},\n",
    "            \"difficulty\": {\"type\": \"float\"},\n",
    "            \"tags\": {\"type\": \"keyword\"},\n",
    "            \"true_title\": {\"type\": \"text\", \"index\": False}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es.indices.create(index=index_name, body=mapping)\n",
    "print(f\"Индекс {index_name} успешно создан с русским анализатором\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV-файл успешно предобработан и загружен в Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from elasticsearch import Elasticsearch\n",
    "from normalize_utils import (\n",
    "    normalize_date,\n",
    "    normalize_difficulty,\n",
    "    normalize_tags,\n",
    "    lemmatize_text,\n",
    "    clean_text\n",
    ")\n",
    "\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "index_name = \"news\"\n",
    "\n",
    "with open(\"news_data.csv\", newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        row[\"date\"] = normalize_date(row.get(\"date\", \"\"))\n",
    "        row[\"difficulty\"] = normalize_difficulty(row.get(\"difficulty\"))\n",
    "        row[\"tags\"] = normalize_tags(row.get(\"tags\"))\n",
    "\n",
    "        # Лемматизируем большие текстовые поля\n",
    "        for field in [\"title\", \"subtitle\", \"text\"]:\n",
    "            if row.get(field):\n",
    "                row[field] = lemmatize_text(clean_text(row[field]))\n",
    "\n",
    "        es.index(index=index_name, document=row)\n",
    "\n",
    "print(\"CSV-файл успешно предобработан и загружен в Elasticsearch\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
